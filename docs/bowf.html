<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Tutorial Note for Bayesian Optimization</title>
  <meta name="description" content="This will provide short introduction to bayesian Otimzation. First, it introduces mathematical foundation then numercal examples." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Tutorial Note for Bayesian Optimization" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This will provide short introduction to bayesian Otimzation. First, it introduces mathematical foundation then numercal examples." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tutorial Note for Bayesian Optimization" />
  
  <meta name="twitter:description" content="This will provide short introduction to bayesian Otimzation. First, it introduces mathematical foundation then numercal examples." />
  

<meta name="author" content="Peyman Kor" />


<meta name="date" content="2021-08-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="numerical-example.html"/>
<script src="libs/header-attrs-2.9.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="bowf.html"><a href="bowf.html"><i class="fa fa-check"></i><b>1</b> Bayesian Optimization Workflow</a>
<ul>
<li class="chapter" data-level="1.1" data-path="bowf.html"><a href="bowf.html#overall-view"><i class="fa fa-check"></i><b>1.1</b> Overall View</a></li>
<li class="chapter" data-level="1.2" data-path="bowf.html"><a href="bowf.html#gaussian-process"><i class="fa fa-check"></i><b>1.2</b> Gaussian Process</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="bowf.html"><a href="bowf.html#step-1-choose-some-initial-design-points-mathcaldmathbfumathbfju-to-build-probabilistic-model-inferred-from-mathcald"><i class="fa fa-check"></i><b>1.2.1</b> Step 1: Choose some initial design points <span class="math inline">\(\mathcal{D}=\{{\mathbf{U},\mathbf{J(U)}}\}\)</span> to build probabilistic model inferred from <span class="math inline">\(\mathcal{D}\)</span></a></li>
<li class="chapter" data-level="1.2.2" data-path="bowf.html"><a href="bowf.html#step.2-deciding-on-next-mathbfunext-based-on-the-probabilistic-model"><i class="fa fa-check"></i><b>1.2.2</b> Step.2 Deciding on next <span class="math inline">\(\mathbf{u}^{next}\)</span> based on the probabilistic model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="numerical-example.html"><a href="numerical-example.html"><i class="fa fa-check"></i><b>2</b> Numerical Example</a>
<ul>
<li class="chapter" data-level="2.1" data-path="numerical-example.html"><a href="numerical-example.html#d-toy-problem"><i class="fa fa-check"></i><b>2.1</b> 1-D Toy Problem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tutorial Note for Bayesian Optimization</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Tutorial Note for Bayesian Optimization</h1>
<p class="author"><em>Peyman Kor</em></p>
<p class="date" style="margin-top: 1.5em;"><em>2021-08-27</em></p>
</div>
<div id="bowf" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Bayesian Optimization Workflow</h1>
<div id="overall-view" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Overall View</h2>
<p>Bayesian Optimization (BO) is an optimization method that builds a probabilistic model to mimic an expensive objection function. The probabilistic model is an inference from a finite number of function evaluations. This finite number of evaluations is done as initialization of the workflow and build a probabilistic model.</p>
<p>After initializing and building a probabilistic model, a new query point is evaluated using the expensive objective function at each iteration. Then the new data <span class="math inline">\((\mathbf{u}^{new},\mathbf{J}(\mathbf{u}^{new}))\)</span> is assimilated back to the probabilistic model to update the model. The unique methodology of using a non-deterministic surrogate model makes Bayesian optimization (BO) an efficient global optimizer capable of exploring and exploiting space of decision.</p>
<p>In the rest of this section, the objective function is shown with <span class="math inline">\(\overline{\mathbf{J}}(\mathbf{u})\)</span>, consistent with the Equation <a href="#eq:npvopt">(<strong>??</strong>)</a>. However, for convention, we drop the bar and write the <span class="math inline">\(\overline{\mathbf{J}}(\mathbf{u})\)</span> with <span class="math inline">\(\mathbf{J}(\mathbf{u})\)</span>. Moreover, <span class="math inline">\(\mathbf{u}\)</span> is a control decision, with a dimension of <span class="math inline">\(D\)</span>, <span class="math inline">\(\mathbf{u}=[u_1,\cdots,u_D]\)</span>. While, the capital letter, <span class="math inline">\(\mathbf{U}\)</span> is collection of <span class="math inline">\(\mathbf{N}\)</span> points of <span class="math inline">\(\mathbf{u}\)</span>, defined as: <span class="math inline">\(\mathbf{U}= [\mathbf{u_1},\cdots,\mathbf{u_N}]\)</span>.</p>
<p>The workflow of BO can be divided into two steps:</p>
<ul>
<li>Step 1: Choose some initial design points <span class="math inline">\(\mathcal{D}=\{{\mathbf{U},\mathbf{J(U)}}\}\)</span> to build a probabilistic model inferred from <span class="math inline">\(\mathcal{D}\)</span></li>
<li>Step 2: Deciding on next <span class="math inline">\(\mathbf{u}^{next}\)</span> and evaluate <span class="math inline">\(\mathbf{J(u^{next})}\)</span> based on probabilistic model and <span class="math inline">\(\mathcal{D}=\mathcal{D}\: \cup[\mathbf{u}^{next},\mathbf{J(u^{next})}]\)</span></li>
</ul>
<p>After step 2, we come back to step 1 with the new <span class="math inline">\(\mathcal{D}\)</span>, and we iterate this process until we are out of computational budget. First, we will explain Gaussian Process (GP) as a method for building a probabilistic model as a background for the workflow. Then, both steps are explained in detail.</p>
</div>
<div id="gaussian-process" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Gaussian Process</h2>
<p>In this work, we employ the widely used Gaussian process (GP) as a probabilistic model. Known as a surrogate model (since it tries to mimic the real, expensive objective function), GP is an attractive choice because it is computationally traceable with the capability to quantify the uncertainty of interest <span class="citation">(<a href="#ref-rasmussen2006" role="doc-biblioref">Rasmussen and Williams 2006</a>; <a href="#ref-murphy2022" role="doc-biblioref">Murphy 2022</a>)</span>. A GP can be seen as an extension of the Gaussian distribution to the functional space. Key assumption in (GP) is that: the function values at a set of <span class="math inline">\(M &gt; 0\)</span> inputs, <span class="math inline">\(\mathbf{J} = [\mathbf{J({u_1})}, ...,\mathbf{J(u_M)}]\)</span>, is jointly Gaussian, with mean and Covariance defined as:</p>
<span class="math display" id="eq:mean-cov">\[\begin{equation}
  \begin{split}
&amp; \mathbb{E} \: [\mathbf{J(u)}]= m(\mathbf{u}) \\
&amp; \text{Cov} \: [\mathbf{J(u)}),J(\mathbf{J(u&#39;)}]= \kappa(\mathbf{u},\mathbf{u&#39;})
  \end{split} \tag{1.1}
\end{equation}\]</span>
<p>In <a href="bowf.html#eq:mean-cov">(1.1)</a>, <span class="math inline">\(m(\mathbf{u})\)</span> is a mean function and <span class="math inline">\(\kappa(\mathbf{u},\mathbf{u&#39;})\)</span> is a covariance function (or kernel). <span class="math inline">\(\kappa(\mathbf{u},\mathbf{u&#39;})\)</span> specifies the similarity between two values of a function evaluated on <span class="math inline">\(\mathbf{u}\)</span>, and <span class="math inline">\(\mathbf{u&#39;}\)</span> . A GP is a distribution over function completely defined by its mean and covariance function as:</p>
<span class="math display" id="eq:mean-cov-gp">\[\begin{equation}
J(\mathbf{u}) \sim \mathcal{N}(m(\mathbf{u}), \kappa(\mathbf{u},\mathbf{u&#39;}))
\tag{1.2}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathcal{N}\)</span> denotes a multivariate normal distribution.As discussed in <span class="citation">(<a href="#ref-shahriari2016" role="doc-biblioref">Shahriari et al. 2016</a>)</span>, there are many choices for the covariance function; the most commonly used ones in the literature have been depicted in Table <a href="bowf.html#tab:cov-tab">1.1</a>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:cov-tab">Table 1.1: </span> Several types of covariance function for the GP process
</caption>
<thead>
<tr>
<th style="text-align:left;">
Covariance Kernels
</th>
<th style="text-align:left;">
assumeing <span class="math inline">\(h=||u-u&#39;||\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Gaussain
</td>
<td style="text-align:left;">
<span class="math inline">\(\Large \kappa (\mathbf{u},\mathbf{u&#39;}) =\sigma_f^2 exp(-\frac{h^2}{2\ell^2})\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Matern <span class="math inline">\(\nu=\frac{5}{2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\Large \kappa (\mathbf{u},\mathbf{u&#39;}) =\sigma_f^2(1 + \frac{\sqrt{5}|h|}{\ell}\frac{5h^2}{3\ell^2})exp(-\frac{ -\sqrt{5}|h|}{\ell})\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Matern <span class="math inline">\(\nu=\frac{3}{2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\Large \kappa (\mathbf{u},\mathbf{u&#39;}) =\sigma_f^2(1 + \frac{\sqrt{3}|h|}{\ell})exp(-\frac{-\sqrt{3}|h|}{\ell})\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Exponetial
</td>
<td style="text-align:left;">
<span class="math inline">\(\Large \kappa (\mathbf{u},\mathbf{u&#39;}) =\sigma_f^2 exp(-\frac{|h|}{\ell})\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Power-Exponetial
</td>
<td style="text-align:left;">
<span class="math inline">\(\Large \kappa (\mathbf{u},\mathbf{u&#39;}) =\sigma_f^2 exp(-(\frac{|h|}{\ell})^p)\)</span>
</td>
</tr>
</tbody>
</table>
<p>Where in the Table <a href="bowf.html#tab:cov-tab">1.1</a>, <span class="math inline">\(\ell\)</span> is length-scale, and <span class="math inline">\(h\)</span> is eludian distance of <span class="math inline">\(\mathbf{u}\)</span>, <span class="math inline">\(\mathbf{u&#39;}\)</span>. ( Note that <span class="math inline">\(|h|^2=(\mathbf{u}-\mathbf{u&#39;})^\intercal(\mathbf{u}-\mathbf{u&#39;})\)</span>). In this work, the Matern covariance function with <span class="math inline">\(\nu=\frac{5}{2}\)</span> was employed. However, depending to any choice of covariance function, the parameters of covariance function needs to be estimated. These parameters can be denoted as <span class="math inline">\(\theta\)</span> as:</p>
<span class="math display" id="eq:cova-theta">\[\begin{equation}
\theta = [\sigma^2_{f},\ell]
\tag{1.3}
\end{equation}\]</span>
<p>The parameter <span class="math inline">\(\theta\)</span> needs to be optimized, as it will be explained later. With this background, BO workflow is explained as follows.</p>
<div id="step-1-choose-some-initial-design-points-mathcaldmathbfumathbfju-to-build-probabilistic-model-inferred-from-mathcald" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Step 1: Choose some initial design points <span class="math inline">\(\mathcal{D}=\{{\mathbf{U},\mathbf{J(U)}}\}\)</span> to build probabilistic model inferred from <span class="math inline">\(\mathcal{D}\)</span></h3>
<p>Assuming we start GP with a finite number of an initial evaluation of <span class="math inline">\(\mathbf{J(u)}\)</span> on the points in <span class="math inline">\(\mathbf{U}\)</span>, we can define the data-set <span class="math inline">\(\mathcal{D}\)</span> as:</p>
<span class="math display" id="eq:init-data">\[\begin{align}
  \begin{split}
\mathbf{U}= &amp; \: [\mathbf{u_1},\cdots,\mathbf{u_N}] \\
\mathbf{J_U}= &amp; \: [\mathbf{J(u_1)},\cdots,\mathbf{J(u_N)}] \\
\mathcal{D}= &amp; \: \{\mathbf{U},\mathbf{\mathbf{J_U}}\}
  \end{split}
\tag{1.4}
\end{align}\]</span>
<p>Now we consider the case of predicting the outputs for new inputs that are not in <span class="math inline">\(\mathcal{D}\)</span>. Specifically, given a test set (prediction set) set <span class="math inline">\(\mathbf{U_*}\)</span> of size <span class="math inline">\(\mathbf{N_* \times D}\)</span>, we want to predict the function outputs <span class="math inline">\(\mathbf{J_{U_*}} = [\mathbf{J(u_1)},\cdots, \mathbf{J(u_{N_*})}]\)</span>. By definition of the GP, the joint distribution <span class="math inline">\(p(\mathbf{J_U}, \mathbf{J_{U_*}})\)</span> has the following form:</p>
<span class="math display" id="eq:gp-model-mat">\[\begin{equation}
\begin{bmatrix}  {\bf {J_U}}  \\  {\mathbf{J_{U_*}}} \end{bmatrix} \sim \mathcal{N} \begin{pmatrix} \begin{bmatrix}  {m(\mathbf{U})}  \\  {m(\mathbf{U_*})} \end{bmatrix},\begin{bmatrix} {{\bf K}_{U,U}}  &amp; {{\bf
K}_{U,U_*}}  \\  {{\bf \mathbf{K}^\intercal}_{U,U_*}} &amp; {{\bf K}_{U_*,U_*} } \end{bmatrix}\end{pmatrix}
\tag{1.5}
\end{equation}\]</span>
<p>Where, <span class="math inline">\(m(\mathbf{U})\)</span> is prior knowledge about mean value of <span class="math inline">\(\mathbf{J_U}\)</span>, defined as <span class="math inline">\(m(\mathbf{U})=[m(\mathbf{u_1}),\cdots,m(\mathbf{u_N})]\)</span>. For simplicity someone can assume the prior mean function to be zero: <span class="math inline">\(m(\mathbf{U}) = 0\)</span>. This assumption is not restrictive because as more training points are observed the prior is updated and becomes more informative. In this work, we considered the case where the mean function could have a linear trend in the form of:</p>
<span class="math display" id="eq:linear-mean">\[\begin{equation}
m(\mathbf{u}) = \sum_{j=1}^p \beta_j \mathbf{u}
\tag{1.6}
\end{equation}\]</span>
<p>The <em>Gram</em> matrix, <span class="math inline">\(\mathbf{K}_{U,U}\)</span>, is <span class="math inline">\(\mathbf{N \times N}\)</span> matrix, with each element is covariance of <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{u&#39;}\)</span>:</p>
<span class="math display" id="eq:kernel-struct">\[\begin{equation}
\mathbf{K}_{U,U}=\kappa(\mathbf{U,U})=\left (
\begin{array}{ccc}
\begin{array}{l}
\kappa(\mathbf{u_1},\mathbf{u_2})
\end{array}
&amp; \cdots &amp; 
\begin{array}{l}
\kappa(\mathbf{u_1},\mathbf{u_N})
\end{array} \\
\vdots &amp; \ddots &amp; \vdots\\
\begin{array}{l}
\kappa(\mathbf{u_N},\mathbf{u_1})
\end{array} &amp;
\cdots &amp; 
\begin{array}{l}
\kappa(\mathbf{u_N},\mathbf{u_N})
\end{array} 
\end{array}
\right )
\tag{1.7}
\end{equation}\]</span>
<p>By the standard rules for conditioning multivariate Gaussian distribution, we can drive the posterior (conditional distribution of <span class="math inline">\(\mathbf{J_{U_*}}\)</span> given the <span class="math inline">\(\mathcal{D}\)</span>) in closed form as follows:</p>
<span class="math display" id="eq:post-mean-cov">\[\begin{align}
  \begin{split}
p(\mathbf{J_{U_*}}|\mathbf{\mathcal{D},\theta)}= &amp; \:  \mathcal{MN}(\mathbf{J_{U_*}| \mathbf{\mu_*},\textstyle \sum_{\ast}}) \\
{\mathbf{\mu_\ast}}= &amp; \:  m(\mathbf{U_\ast}) +\mathbf{K}^\intercal_{U,U_*} \mathbf{K}^{-1}_{U,U}(\mathbf{J_U}-m(\mathbf{U})) \\
\textstyle \sum_{\ast}=&amp; \:  \normalsize{\mathbf{K}_{U_\ast,U_\ast}-\mathbf{K}^\intercal_{U,U_\ast}\mathbf{K}_{U,U}^{-1}\mathbf{K}_{U,U_\ast}}
  \end{split}
\tag{1.8}
\end{align}\]</span>
<p>The conditional probability of the <span class="math inline">\(\mathbf{J_{U_*}}\)</span> Equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a> is conditioned on <span class="math inline">\(\mathcal{D}\)</span> meaning the available data points to be inferred, and <span class="math inline">\(\theta\)</span> which is parameters of covariance function, as shown in Equation.</p>
<div id="parameter-estimation-of-covariance-kernel" class="section level4" number="1.2.1.1">
<h4><span class="header-section-number">1.2.1.1</span> Parameter Estimation of Covariance Kernel</h4>
<p>As it shown in the <a href="bowf.html#tab:cov-tab">1.1</a>, the Matern Covariance function with <span class="math inline">\(\nu=\frac{5}{2}\)</span> has two parameters to be estimated, namely <span class="math inline">\(\sigma^2_f\)</span> and <span class="math inline">\(\ell\)</span>. GP is fit to the data by optimizing the evidence-the marginal probability of the data given the model with respect to the marginalized kernel parameters. Known as the empirical Bayes approach, we will maximize the marginal likelihood:</p>
<span class="math display" id="eq:marg-like-int">\[\begin{equation}
p(\mathbf{y}|\mathbf{J_U,\mathbf{\theta}})= \int p(\mathbf{y}|\mathbf{J_U})p(\mathbf{J_U}|\mathbf{\theta})d\mathbf{J}
\tag{1.9}
\end{equation}\]</span>
<p>The term <span class="math inline">\(p(\mathbf{y}|\mathbf{J_U,\mathbf{\theta}})\)</span> in fact represent the probability of observing the data <span class="math inline">\(y\)</span>given on the model, <span class="math inline">\(\mathbf{J_U,\mathbf{\theta}}\)</span>. The reason it is called the marginal likelihood, rather than just likelihood, is because we have marginalized out the latent Gaussian vector <span class="math inline">\(\mathbf{J_U}\)</span>. The <span class="math inline">\(log\)</span> of marginal likelihood then can be written as:</p>
<span class="math display" id="eq:log-like">\[\begin{equation}
\text{log} \: p(\mathbf{y}|\mathbf{J_U,\mathbf{\theta}})=\mathcal{L}(\sigma_f^2,\ell)=-\frac{1}{2}(\mathbf{y}-m(\mathbf{U}))^{\intercal}\mathbf{K}_{U,U}^{-1}(\mathbf{y}-m(\mathbf{U}))-\frac{1}{2}\text{log}|\mathbf{K}_{U,U}|-\frac{N}{2}log(2\pi)
\tag{1.10}
\end{equation}\]</span>
<p>Where the dependence of the <span class="math inline">\(\mathbf{K}_{U,U}\)</span> on <span class="math inline">\(\theta\)</span> is implicit. This objective function consists of a model fit and a complexity penalty term that results in an automatic Occam’s razor for realizable functions <span class="citation">(<a href="#ref-rasmussen2006" role="doc-biblioref">Rasmussen and Williams 2006</a>)</span>. By optimizing the evidence with respect to the kernel hyperparameters, we effectively learn the structure of the space of functional relationships between the inputs and the targets. The gradient-based optimizer is performed in order to:</p>
<span class="math display" id="eq:log-like-opt">\[\begin{equation}
\theta^{\ast}=[\sigma_f^{2\ast}, \ell^{\ast}]=argmax \: \mathcal{L}(\sigma^2_f,\ell)
\tag{1.11}
\end{equation}\]</span>
<p>However, since the objective <span class="math inline">\(\mathcal{L}\)</span> is not convex, local minima can be a problem, so we need to use multiple restarts.</p>
<p>It is useful to note that the value <span class="math inline">\(\theta^{\ast}\)</span> could be estimated using only a “initial data,” <span class="math inline">\(\mathcal{D}=[\mathbf{U},\mathbf{J_U}]\)</span>. Therefore Equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a> can be written using the “optimized” value of <span class="math inline">\(\theta\)</span>. Moreover, given that in next step usually, we need probability distribution of <span class="math inline">\(\mathbf{J}\)</span> for each control value (<span class="math inline">\(\mathbf{u}\)</span>), equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a> can be written as:</p>
<span class="math display" id="eq:post-mean-cov-single">\[\begin{align}
  \begin{split}
p(\mathbf{J_{u_*}}|\mathbf{\mathcal{D},\theta^\ast})= &amp; \:  \mathcal{N}(\mathbf{J_{u_*}}| \mathbf{\mu_{u_\ast}}, \mathbf{\sigma^2_{u_{\ast}}}) \\
\mathbf{\mu_{u_\ast}}= &amp; \:  m(\mathbf{u_\ast}) +\mathbf{K}^\intercal_{U,u_*} \mathbf{K}^{-1}_{U,U}(\mathbf{J_U}-m(\mathbf{U})) \\
\textstyle \sigma^2_{\mathbf{u_{\ast}}}=&amp; \:  \normalsize{\mathbf{\kappa}_{u_\ast,u_\ast}-\mathbf{K}^\intercal_{U,u_\ast}\mathbf{K}_{U,U}^{-1}\mathbf{K}_{U,u_\ast}}
  \end{split}
\tag{1.12}
\end{align}\]</span>
<p>In <a href="bowf.html#eq:post-mean-cov-single">(1.12)</a>, we replaced the <span class="math inline">\(\mathcal{MN}\)</span> with <span class="math inline">\(\mathcal{N}\)</span> in <a href="bowf.html#eq:post-mean-cov">(1.8)</a> as Equation <a href="bowf.html#eq:post-mean-cov-single">(1.12)</a> shows the probability of <span class="math inline">\(\mathbf{J}\)</span> for <em>one</em> control variable, wherein Equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a> we have th probality of the <span class="math inline">\(\mathbf{J}\)</span>, over a vector of the control variable, <span class="math inline">\(\mathbf{U}\)</span>.</p>
</div>
</div>
<div id="step.2-deciding-on-next-mathbfunext-based-on-the-probabilistic-model" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Step.2 Deciding on next <span class="math inline">\(\mathbf{u}^{next}\)</span> based on the probabilistic model</h3>
<p>The posterior of the probabilistic model given by Equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a> can quantify the uncertainty over the space of the unknown function, <span class="math inline">\(f\)</span>. The question is, what is the next <span class="math inline">\(\mathbf{u}^{next}\)</span> to feed into the <em>expensive function</em>?. In other words, so far we have <span class="math inline">\(\mathcal{D}\)</span>, but need to decide the next <span class="math inline">\(\mathbf{u}^{next}\)</span> so that going back to Step 1, our updated <span class="math inline">\(\mathcal{D}\)</span> be <span class="math inline">\(\mathcal{D}=\mathcal{D} \: \cup[\mathbf{u^{next}},\mathbf{J(u^{next})}]\)</span>. One could select the next point arbitrarily, but that would be wasteful.</p>
<p>To answer this question, we define a utility function, and the next query point is the point that with maximum utility. The literature of BO has seen many utility functions (called acquisition function in the computer science community). These include the Improvement based policies (Probability of Improvement (PI), Expected Improvement(EI)), optimistic policies (Upper Confidence Bound (UCB)), or Information-based (like Thompson Sampling (TS)). The full review of these utility functions and their strength and weakness could be reviewed in <span class="citation">(<a href="#ref-shahriari2016" role="doc-biblioref">Shahriari et al. 2016</a>)</span>.</p>
<p>In the Expected Improvement (EI) policy, the utility is defined as follows:</p>
<span class="math display" id="eq:utiint">\[\begin{equation}
utility(\mathbf{u_\ast};\theta^{\ast},\mathcal{D})=\alpha_{EI}(\mathbf{u_\ast};\theta^\ast,\mathcal{D})=\int_{y}^{}max(0,\mathbf{J_{u_*}}-f)p(\mathbf{J_{u_*}}|\mathbf{\mathcal{D},\theta^\ast}) \,dy
\tag{1.13}
\end{equation}\]</span>
<p>The utility defined in Equation @(ref:utiint) can be seen as the expected value of improvement in posterior of the model (Equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a>) compared to the <em>true function</em> at point <span class="math inline">\(\mathbf{u_\ast}\)</span>. Note that the term <span class="math inline">\(p(\mathbf{J_{u_*}}|\mathbf{\mathcal{D},\theta^\ast})\)</span> inside the integral already has been defined at Equation <a href="bowf.html#eq:post-mean-cov">(1.8)</a>. However, we do not have access to the <em>expensive function</em>, <span class="math inline">\(f\)</span>; therefore, we replace the <span class="math inline">\(f\)</span> with the best available solution found so far, <span class="math inline">\(\mathbf{J}^+\)</span>. The <span class="math inline">\(\mathbf{J^+}\)</span> mathematically can be defined simply as below, then Equation <a href="bowf.html#eq:utiint">(1.13)</a> can be written as Equation <a href="bowf.html#eq:utiint2">(1.15)</a>:</p>
<span class="math display" id="eq:j-plus">\[\begin{equation}
\begin{aligned}
\mathbf{J^+} = \; \underset{\mathbf{u} \subseteq \mathcal{D}}{\text{max}}
\; \mathbf{J(u)}
\end{aligned}
\tag{1.14}
\end{equation}\]</span>
<span class="math display" id="eq:utiint2">\[\begin{equation}
\alpha_{EI}(\mathbf{u_\ast};\theta^\ast,\mathcal{D})=\int_{y}^{}max(0,\mathbf{J_{u_*}}-\mathbf{J^+})p(\mathbf{J_{u_*}}|\mathbf{\mathcal{D},\theta^\ast}) \,dy
\tag{1.15}
\end{equation}\]</span>
<p>After applying some tedious integration by parts on the right side of <a href="bowf.html#eq:utiint2">(1.15)</a>, one can express the expected improvement in a closed form <span class="citation">(<a href="#ref-jones1998" role="doc-biblioref">Jones, Schonlau, and Welch 1998</a>)</span>. To achieve closed form, first, we need some parametrization and define the <span class="math inline">\(\gamma(\mathbf{u_*})\)</span> as below:</p>
<span class="math display" id="eq:gamma">\[\begin{equation}
\gamma(\mathbf{u_*})=\frac{\mathbf{\mu_{u_\ast}}-\mathbf{J^+}}{\sigma_\mathbf{u_{\ast}}}
\tag{1.16}
\end{equation}\]</span>
<p>Where <span class="math inline">\(\mathbf{\mu_{u_\ast}}\)</span> and <span class="math inline">\(\sigma_\mathbf{u_{\ast}}\)</span> can be found from Eqaution <a href="bowf.html#eq:post-mean-cov-single">(1.12)</a> and <span class="math inline">\(\mathbf{J^+}\)</span> has been defined in Equation <a href="bowf.html#eq:j-plus">(1.14)</a>. Given the <span class="math inline">\(\gamma(\mathbf{u_*})\)</span>, the right side of Equation <a href="bowf.html#eq:utiint2">(1.15)</a> can be written as:</p>
<span class="math display" id="eq:utility">\[\begin{equation}
\alpha_{EI}(\mathbf{u_*};\theta^*,\mathcal{D})=(\mathbf{\mu_{u_\ast}}-\mathbf{J^+})\Phi(\gamma(\mathbf{u
_*})) + \sigma_{\mathbf{u_{\ast}}} \phi(\gamma(\mathbf{u_*}))
\tag{1.17}
\end{equation}\]</span>
<p>Where <span class="math inline">\(\Phi(.)\)</span> and <span class="math inline">\(\phi(.)\)</span> are CDF and PDF of standard Gaussian distribution. We need to note that <span class="math inline">\(\alpha_{EI}(\mathbf{u_*};\theta^*,\mathcal{D})\)</span> is always non-negative, as the integral defined in <a href="bowf.html#eq:utiint2">(1.15)</a> is truncating the negative side of the function <span class="math inline">\(\mathbf{J}\)</span> inside the <span class="math inline">\(max()\)</span> term. The Equation<a href="bowf.html#eq:utility">(1.17)</a> does a fine job in many applications of Bayesian Optimization. However, the utility defined in Equation <a href="bowf.html#eq:utility">(1.17)</a> sometimes can be <em>greedy</em>. In this context, greedy utility means that it is focused more on the “immediate reward,” which is the first part of Equation <a href="bowf.html#eq:utility">(1.17)</a>, less on the “Exploration” part. Therefore to avoid this greed and make the utility function more forward-looking, an explorative term is added as <span class="math inline">\(\epsilon\)</span>, and Equation <a href="bowf.html#eq:gamma">(1.16)</a> can be re-written as:</p>
<span class="math display" id="eq:gamma-no-greed">\[\begin{equation}
\gamma(\mathbf{u_*})=\frac{\mathbf{\mu_{u_\ast}}-\mathbf{J^+}-\epsilon}{\sigma^2_{\mathbf{u_{\ast}}}}
\tag{1.18}
\end{equation}\]</span>
<p>Likewise, Expected improvement (EI) at point <span class="math inline">\(\mathbf{u_*}\)</span> can be defined then as:</p>
<span class="math display" id="eq:utility-no-greed">\[\begin{equation}
\alpha_{EI}(\mathbf{u_*};\theta,\mathcal{D})=(\mathbf{\mu_{u_\ast}}-\mathbf{J^+}-\epsilon)\Phi(\gamma(\mathbf{u
_*})) + \sigma_{\mathbf{u_{\ast}}} \phi(\gamma(\mathbf{u_*}))
\tag{1.19}
\end{equation}\]</span>
<p>In this work, the utility defined in Equation <a href="bowf.html#eq:utility-no-greed">(1.19)</a> was considered. The data <span class="math inline">\(\mathcal{D}\)</span> was normalized to the scale of <span class="math inline">\([0,1]\)</span>. Given that scaling, <span class="math inline">\(\epsilon=0.1\)</span> was used in this work. At the end, the answer to the question of the next query is the point where the utility is maximum, can be defined as:</p>
<span class="math display" id="eq:exp-easy">\[\begin{equation}
\mathbf{u}_*^{next}=\underset{\mathbf{u_*} \in \mathbf{U_*} }{\mathrm{argmax}} \; \alpha_{EI}(\mathbf{u_*};\theta,\mathcal{D})
\tag{1.20}
\end{equation}\]</span>
<p>The Equation in <a href="bowf.html#eq:exp-easy">(1.20)</a> represents a need for internal optimization in each iteration of BO. However, worth noting that the optimization of Equation <a href="bowf.html#eq:exp-easy">(1.20)</a> is not computationally difficult for two main reasons. First, the forward evaluation of the Equation <a href="bowf.html#eq:exp-easy">(1.20)</a>, <span class="math inline">\(\alpha_{EI}(\mathbf{u_*};\theta,\mathcal{D})\)</span> is inexpensive. In other words, we have a simple analytical formaula for calculating the <span class="math inline">\(\alpha_{EI}(\mathbf{u_*};\theta,\mathcal{D})\)</span>, as it has been provided in Equation <a href="bowf.html#eq:utility-no-greed">(1.19)</a>. Secondly, the exact analytical expression of the Equation <a href="bowf.html#eq:utility-no-greed">(1.19)</a> is available. Authors refer to <span class="citation">(<a href="#ref-rasmussen2006" role="doc-biblioref">Rasmussen and Williams 2006</a>)</span> for detail of mathematical formulation. Having the gradient of the function in addition to inexpensive forward function, make the gradient-based method a suitable optimization choice. In this work, the quasi-Newton family of gradient based method, BFGS is used for finding <span class="math inline">\(\mathbf{u}_*^{next}\)</span>. Multi-start BFGS were performed to avoid local optima points <span class="citation">(<a href="#ref-nocedal2006" role="doc-biblioref">Nocedal and Wright 2006</a>; <a href="#ref-byrd1995" role="doc-biblioref">Byrd et al. 1995</a>)</span>.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-byrd1995" class="csl-entry">
Byrd, Richard H., Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. 1995. <span>“A Limited Memory Algorithm for Bound Constrained Optimization.”</span> <em>SIAM Journal on Scientific Computing</em> 16 (September): 1190–1208. <a href="https://doi.org/10.1137/0916069">https://doi.org/10.1137/0916069</a>.
</div>
<div id="ref-jones1998" class="csl-entry">
Jones, Donald R., Matthias Schonlau, and William J. Welch. 1998. <span>“Efficient Global Optimization of Expensive Black-Box Functions.”</span> <em>Journal of Global Optimization</em> 13 (4): 455–92. <a href="https://doi.org/10.1023/A:1008306431147">https://doi.org/10.1023/A:1008306431147</a>.
</div>
<div id="ref-murphy2022" class="csl-entry">
Murphy, Kevin P. 2022. <em>Probabilistic Machine Learning: An Introduction</em>. MIT Press.
</div>
<div id="ref-nocedal2006" class="csl-entry">
Nocedal, Jorge, and Stephen J. Wright. 2006. <em>Numerical Optimization</em>. 2nd ed. Springer Series in Operations Research. New York: Springer.
</div>
<div id="ref-rasmussen2006" class="csl-entry">
Rasmussen, Carl Edward, and Christopher K. I. Williams. 2006. <em>Gaussian Processes for Machine Learning</em>. Adaptive Computation and Machine Learning. Cambridge, Mass: MIT Press.
</div>
<div id="ref-shahriari2016" class="csl-entry">
Shahriari, Bobak, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Freitas. 2016. <span>“Taking the Human Out of the Loop: A Review of Bayesian Optimization.”</span> <em>Proceedings of the IEEE</em> 104 (1): 148–75. <a href="https://doi.org/10.1109/JPROC.2015.2494218">https://doi.org/10.1109/JPROC.2015.2494218</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="numerical-example.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BO_Guide_Booklet.pdf", "BO_Guide_Booklet.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
